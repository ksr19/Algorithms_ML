{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 1. Алгоритм линейной регрессии. Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 1,  1],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2],\n",
    "              [ 1,  5],\n",
    "              [ 1,  3],\n",
    "              [ 1,  0],\n",
    "              [ 1,  5],\n",
    "              [ 1, 10],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 1], y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(y, y_pred):\n",
    "    err = np.mean(np.abs(y - y_pred))\n",
    "    return err\n",
    "\n",
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подберите скорость обучения (eta) и количество итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.075        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [ 9.1   28.775], MSE = 3047.75\n",
      "Iteration #100: W_new = [44.53105929  3.90886858], MSE = 44.10907488\n",
      "Iteration #200: W_new = [44.95885848  3.83129379], MSE = 43.97391364\n",
      "Iteration #300: W_new = [45.00712624  3.82254118], MSE = 43.97020556\n",
      "Iteration #400: W_new = [45.01899245  3.82038942], MSE = 43.96964424\n",
      "Iteration #500: W_new = [45.02285255  3.81968945], MSE = 43.96949122\n",
      "Iteration #600: W_new = [45.02424717  3.81943656], MSE = 43.9694395\n",
      "Iteration #700: W_new = [45.0247716   3.81934146], MSE = 43.96942054\n",
      "Iteration #800: W_new = [45.02497185  3.81930515], MSE = 43.96941337\n",
      "Iteration #900: W_new = [45.02504877  3.8192912 ], MSE = 43.96941063\n",
      "Iteration #1000: W_new = [45.02507839  3.81928583], MSE = 43.96940957\n",
      "Iteration #1100: W_new = [45.0250898   3.81928376], MSE = 43.96940916\n",
      "Iteration #1200: W_new = [45.0250942   3.81928297], MSE = 43.96940901\n",
      "Iteration #1300: W_new = [45.02509589  3.81928266], MSE = 43.96940895\n",
      "Iteration #1400: W_new = [45.02509655  3.81928254], MSE = 43.96940892\n",
      "Iteration #1500: W_new = [45.0250968   3.81928249], MSE = 43.96940892\n",
      "Iteration #1600: W_new = [45.02509689  3.81928248], MSE = 43.96940891\n",
      "Iteration #1700: W_new = [45.02509693  3.81928247], MSE = 43.96940891\n",
      "Iteration #1800: W_new = [45.02509695  3.81928247], MSE = 43.96940891\n",
      "Iteration #1900: W_new = [45.02509695  3.81928247], MSE = 43.96940891\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "\n",
    "# Обновленные значения скорости обучения и количества итераций\n",
    "eta = 7.5e-2\n",
    "n_iter = 2000\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "        W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    if i % 10 == 0:\n",
    "        eta /= 1.1\n",
    "    # Сделал вывод результатов на каждой 100ой итерации для удобства отображения\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err, 8)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.0625,  3.8125])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_analytical = np.linalg.inv(np.dot(X.T, X)) @ X.T @ y\n",
    "W_analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.96875000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.dot(X, W_analytical)\n",
    "err = calc_mse(y, y_pred)\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличия от аналитического решения присутствуют, но они значительно меньше, чем при изначально выбранных параметрах скорости обучения и количество итераций. <br>\n",
    "Можно воспользоваться другим подходом: взять довольно маленькое значение скорости обучения, которое не будет меняться в процессе спуска, и большое количество итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 6e-05        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [1.00648 0.52262], MSE = 3047.75\n",
      "Iteration #10000: W_new = [20.7190045   8.22681757], MSE = 323.11094525\n",
      "Iteration #20000: W_new = [30.97829142  6.36645407], MSE = 137.40695958\n",
      "Iteration #30000: W_new = [36.91391955  5.29011943], MSE = 75.2456374\n",
      "Iteration #40000: W_new = [40.3480453   4.66739367], MSE = 54.43816813\n",
      "Iteration #50000: W_new = [42.33489815  4.30710854], MSE = 47.47321368\n",
      "Iteration #60000: W_new = [43.48441466  4.09866145], MSE = 45.14181096\n",
      "Iteration #70000: W_new = [44.14948062  3.97806199], MSE = 44.36141266\n",
      "Iteration #80000: W_new = [44.53426217  3.90828779], MSE = 44.1001873\n",
      "Iteration #90000: W_new = [44.75688194  3.86791912], MSE = 44.01274645\n",
      "Iteration #100000: W_new = [44.88568117  3.84456337], MSE = 43.98347708\n",
      "Iteration #110000: W_new = [44.96019944  3.83105063], MSE = 43.97367965\n",
      "Iteration #120000: W_new = [45.00331283  3.82323268], MSE = 43.97040012\n",
      "Iteration #130000: W_new = [45.02825659  3.81870952], MSE = 43.96930235\n",
      "Iteration #140000: W_new = [45.04268808  3.81609259], MSE = 43.96893489\n",
      "Iteration #150000: W_new = [45.05103759  3.81457853], MSE = 43.96881189\n",
      "Iteration #160000: W_new = [45.05586829  3.81370256], MSE = 43.96877072\n",
      "Iteration #170000: W_new = [45.05866315  3.81319575], MSE = 43.96875693\n",
      "Iteration #180000: W_new = [45.06028015  3.81290254], MSE = 43.96875232\n",
      "Iteration #190000: W_new = [45.06121568  3.81273289], MSE = 43.96875078\n",
      "Iteration #200000: W_new = [45.06175694  3.81263474], MSE = 43.96875026\n",
      "Iteration #210000: W_new = [45.06207009  3.81257796], MSE = 43.96875009\n",
      "Iteration #220000: W_new = [45.06225127  3.8125451 ], MSE = 43.96875003\n",
      "Iteration #230000: W_new = [45.0623561   3.81252609], MSE = 43.96875001\n",
      "Iteration #240000: W_new = [45.06241674  3.8125151 ], MSE = 43.96875\n",
      "Iteration #250000: W_new = [45.06245183  3.81250873], MSE = 43.96875\n",
      "Iteration #260000: W_new = [45.06247213  3.81250505], MSE = 43.96875\n",
      "Iteration #270000: W_new = [45.06248388  3.81250292], MSE = 43.96875\n",
      "Iteration #280000: W_new = [45.06249067  3.81250169], MSE = 43.96875\n",
      "Iteration #290000: W_new = [45.0624946   3.81250098], MSE = 43.96875\n",
      "Iteration #300000: W_new = [45.06249688  3.81250057], MSE = 43.96875\n",
      "Iteration #310000: W_new = [45.06249819  3.81250033], MSE = 43.96875\n",
      "Iteration #320000: W_new = [45.06249895  3.81250019], MSE = 43.96875\n",
      "Iteration #330000: W_new = [45.0624994   3.81250011], MSE = 43.96875\n",
      "Iteration #340000: W_new = [45.06249965  3.81250006], MSE = 43.96875\n",
      "Iteration #350000: W_new = [45.0624998   3.81250004], MSE = 43.96875\n",
      "Iteration #360000: W_new = [45.06249988  3.81250002], MSE = 43.96875\n",
      "Iteration #370000: W_new = [45.06249993  3.81250001], MSE = 43.96875\n",
      "Iteration #380000: W_new = [45.06249996  3.81250001], MSE = 43.96875\n",
      "Iteration #390000: W_new = [45.06249998  3.8125    ], MSE = 43.96875\n",
      "Iteration #400000: W_new = [45.06249999  3.8125    ], MSE = 43.96875\n",
      "Iteration #410000: W_new = [45.06249999  3.8125    ], MSE = 43.96875\n",
      "Iteration #420000: W_new = [45.0625  3.8125], MSE = 43.96875\n",
      "Iteration #430000: W_new = [45.0625  3.8125], MSE = 43.96875\n",
      "Iteration #440000: W_new = [45.0625  3.8125], MSE = 43.96875\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "\n",
    "# Обновленные значения скорости обучения и количества итераций\n",
    "eta = 6e-5\n",
    "n_iter = 450000\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "        W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "#     if i % 10 == 0:\n",
    "#         eta /= 1.1\n",
    "#   Сделал вывод результатов на каждой 10000ой итерации для удобства отображения\n",
    "    if i % 10000 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err, 8)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2*. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 7.0011236 10.6169007], MSE = 738.65\n",
      "Iteration #20: W_new = [10.3486292  10.10603105], MSE = 622.03\n",
      "Iteration #30: W_new = [13.38789582  9.55618391], MSE = 525.24\n",
      "Iteration #40: W_new = [16.16088505  9.05336203], MSE = 444.66\n",
      "Iteration #50: W_new = [18.69110735  8.59454545], MSE = 377.58\n",
      "Iteration #60: W_new = [20.99981865  8.17589626], MSE = 321.72\n",
      "Iteration #70: W_new = [23.10641138  7.79389815], MSE = 275.22\n",
      "Iteration #80: W_new = [25.02858024  7.44534246], MSE = 236.5\n",
      "Iteration #90: W_new = [26.78247081  7.12730145], MSE = 204.27\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "eta = 1e-2 \n",
    "n_iter = 100\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    # ИЗМЕНЕНИЯ\n",
    "    # W -= eta * (1/n * 2 * np.dot(X, y_pred - y)) \n",
    "\n",
    "    # в изначальном коде неправильно рассчитывается градиент \n",
    "    # необходимо умножать на транспонированную матрицу признаков\n",
    "    W -= eta * (1/n * 2 * np.dot(X.T, y_pred - y))\n",
    "    #\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3*. Вместо того, чтобы задавать количество итераций, задайте другое условие останова алгоритма - когда веса перестают изменяться меньше определенного порога $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.05        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: Learning_rate = 0.04901961, W_new = [1.  0.5], MSE = 3047.75\n",
      "Iteration #100: Learning_rate = 0.04021315, W_new = [44.42588329  3.92794063], MSE = 44.1596334\n",
      "Iteration #200: Learning_rate = 0.03298879, W_new = [45.04178005  3.81625724], MSE = 43.9689522\n",
      "Iteration #300: Learning_rate = 0.02706230, W_new = [45.06124129  3.81272825], MSE = 43.96875075\n",
      "Iteration #400: Learning_rate = 0.02220051, W_new = [45.06237279  3.81252307], MSE = 43.96875001\n",
      "Iteration #500: Learning_rate = 0.01821215, W_new = [45.06248052  3.81250353], MSE = 43.96875\n",
      "Iteration #600: Learning_rate = 0.01494031, W_new = [45.06249581  3.81250076], MSE = 43.96875\n",
      "Iteration #700: Learning_rate = 0.01225626, W_new = [45.06249881  3.81250022], MSE = 43.96875\n",
      "\n",
      "Result:\n",
      "Iteration #725: Learning_rate = 0.01178033, W_new = [45.0624991   3.81250016], MSE = 43.96875\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "\n",
    "eta = 5e-2\n",
    "eps = 1e-8\n",
    "iter_num = 0\n",
    "weight_dist = np.inf\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "while weight_dist > eps:\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    new_W = W - eta * (1/n * 2 * np.dot(X.T, y_pred - y))\n",
    "    weight_dist = np.linalg.norm(new_W - W, ord=2)\n",
    "    if iter_num % 10 == 0:\n",
    "        eta /= 1.02\n",
    "    # Сделал вывод результатов на каждой 100ой итерации для удобства отображения\n",
    "    if iter_num % 100 == 0:\n",
    "        print(f'Iteration #{iter_num}: Learning_rate = {eta:.8f}, W_new = {W}, MSE = {round(err, 8)}')\n",
    "    iter_num += 1\n",
    "    W = new_W\n",
    "\n",
    "print(f'\\nResult:\\nIteration #{iter_num}: Learning_rate = {eta:.8f}, W_new = {W}, MSE = {round(err, 8)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
